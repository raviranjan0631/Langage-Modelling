{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni_f7nkILjA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cS1q1gSa__D",
        "colab_type": "text"
      },
      "source": [
        "## Collect Data\n",
        "Download data from Project Gutenberg site -> http://www.gutenberg.org/files/1342/1342-0.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLe4llafa7H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c444cdc4-a9c2-4133-9a9b-500517420267"
      },
      "source": [
        "book_text = open('1342-0.txt', encoding='utf8').read()\n",
        "print('Length of the book: ', len(book_text))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the book:  775741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXSsNOHRm9YB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ea93a63-4a02-4daf-dd32-710f024bba1e"
      },
      "source": [
        "print(book_text[0:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n",
            "The Proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEeYuZcybof5",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCp9l8cBbnUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c4efe90e-49d3-4aa6-d108-f63d091876e9"
      },
      "source": [
        "t = tf.keras.preprocessing.text.Tokenizer(char_level = True)\n",
        "t.fit_on_texts(book_text)\n",
        "vocab_size = len(t.word_index)\n",
        "print('Number of unique characters: ', vocab_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique characters:  66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjnvrF2BlzGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2c39ed3-c086-4b72-fc53-a10b7a25a7f3"
      },
      "source": [
        "t.word_index"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 15,\n",
              " ' ': 1,\n",
              " '!': 36,\n",
              " '#': 59,\n",
              " '$': 63,\n",
              " '%': 66,\n",
              " \"'\": 61,\n",
              " '(': 46,\n",
              " ')': 47,\n",
              " '*': 49,\n",
              " ',': 22,\n",
              " '-': 38,\n",
              " '.': 24,\n",
              " '/': 51,\n",
              " '0': 48,\n",
              " '1': 41,\n",
              " '2': 42,\n",
              " '3': 43,\n",
              " '4': 44,\n",
              " '5': 45,\n",
              " '6': 50,\n",
              " '7': 54,\n",
              " '8': 52,\n",
              " '9': 53,\n",
              " ':': 40,\n",
              " ';': 29,\n",
              " '?': 37,\n",
              " '@': 62,\n",
              " '[': 58,\n",
              " ']': 60,\n",
              " '_': 32,\n",
              " 'a': 4,\n",
              " 'b': 21,\n",
              " 'c': 16,\n",
              " 'd': 11,\n",
              " 'e': 2,\n",
              " 'f': 19,\n",
              " 'g': 20,\n",
              " 'h': 8,\n",
              " 'i': 6,\n",
              " 'j': 30,\n",
              " 'k': 26,\n",
              " 'l': 12,\n",
              " 'm': 14,\n",
              " 'n': 7,\n",
              " 'o': 5,\n",
              " 'p': 23,\n",
              " 'q': 35,\n",
              " 'r': 10,\n",
              " 's': 9,\n",
              " 't': 3,\n",
              " 'u': 13,\n",
              " 'v': 25,\n",
              " 'w': 18,\n",
              " 'x': 33,\n",
              " 'y': 17,\n",
              " 'z': 31,\n",
              " 'à': 57,\n",
              " 'é': 65,\n",
              " 'ê': 56,\n",
              " '—': 39,\n",
              " '‘': 55,\n",
              " '’': 34,\n",
              " '“': 27,\n",
              " '”': 28,\n",
              " '\\ufeff': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgx7MVC_bkxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert characters in the book to Numbers\n",
        "book_num = t.texts_to_sequences(book_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrLKrAlBmvGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b7193a40-c246-4507-f62e-9d7ecaf94f6c"
      },
      "source": [
        "print(book_num[0:10])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[64], [15], [3], [8], [2], [1], [23], [10], [5], [30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3JLpTSHc4xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build a dictionary which can convert numbers into chars\n",
        "int_to_char = dict((i,c) for c, i in t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1u1ZwUKdiHo",
        "colab_type": "text"
      },
      "source": [
        "## Batch Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPlazYzdfqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AbGd7wdnWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record_num = 0\n",
        "sequence_length = 100\n",
        "def batch_generator(batch_size=32):\n",
        "  global record_num\n",
        "  while True:\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      input_seq = book_num[(record_num * sequence_length):(record_num * sequence_length)+sequence_length]\n",
        "      output_seq = book_num[(record_num * sequence_length)+sequence_length]\n",
        "      \n",
        "      input_data.append(input_seq)\n",
        "      output_data.append(output_seq)\n",
        "\n",
        "      record_num = record_num + 1\n",
        "\n",
        "      if((record_num*sequence_length + sequence_length) > len(book_num)):\n",
        "        record_num = 0\n",
        "    \n",
        "    input_data = tf.keras.utils.to_categorical(input_data,num_classes=vocab_size+1)\n",
        "    #Output data one hot encoding\n",
        "    output_data = tf.keras.utils.to_categorical(output_data,num_classes=vocab_size+1)\n",
        "    #Reshape input data into 3 dimensional numpy array\n",
        "    #batch_size x sequence_length x vocab_size+1\n",
        "    input_data = np.reshape(input_data,(len(input_data),sequence_length,vocab_size+1))\n",
        "    yield input_data, output_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7_NGsGng-bF",
        "colab_type": "text"
      },
      "source": [
        "## Build a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1xTR5w_g1Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(256, input_shape=(sequence_length,vocab_size+1)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(vocab_size+1, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soKp-2PZioJk",
        "colab_type": "text"
      },
      "source": [
        "## Print model output during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT67cE5DinJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_pos = np.random.randint(0, high=(len(book_num)-sequence_length))\n",
        "test_seq = book_num[start_pos: start_pos + sequence_length]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Re_wewyhEXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "268bc17c-585a-44a5-f4fd-382bb0ae1929"
      },
      "source": [
        "print('Initial sequence is: ')\n",
        "for i in range (sequence_length):\n",
        "  print(int_to_char[test_seq[i][0]], end='')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial sequence is: \n",
            "n the place, and his intrigues,\n",
            "      all honoured with the title of seduction, had been extended in"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM-sBUc-jblu",
        "colab_type": "text"
      },
      "source": [
        "## Prediction function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcuiGSJ5hICN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_seq(epoch, logs):\n",
        "  print('\\n\\nOutput sequence after epoch ', epoch, ' :')\n",
        "  \n",
        "  #Initialize predicted output\n",
        "  predicted_output = ''\n",
        "  \n",
        "  #lets predict 50 next chars\n",
        "  current_seq = np.copy(test_seq)\n",
        "  \n",
        "  for i in range(50):\n",
        "    current_seq_one_hot = tf.keras.utils.to_categorical(current_seq, num_classes=vocab_size+1)\n",
        "    data_input = np.reshape(current_seq_one_hot,(1,current_seq_one_hot.shape[0],current_seq_one_hot.shape[1]))\n",
        "    print(data_input.shape)\n",
        "    #Get the char int with maximum probability\n",
        "    predicted_char_int = np.argmax(model.predict(data_input)[0])\n",
        "    \n",
        "    #Add to the predicted out, convert int to char\n",
        "    predicted_output = predicted_output + int_to_char[predicted_char_int]\n",
        "    \n",
        "    #Update seq with new value at the end\n",
        "    current_seq = np.roll(current_seq, -1)\n",
        "    current_seq[current_seq.shape[0]-1] = [predicted_char_int]\n",
        "  \n",
        "  print(predicted_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrtl1zJTjqxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a LabdaCallback to do prediction at end of every epoch\n",
        "lambda_checkpoint = tf.keras.callbacks.LambdaCallback(on_epoch_end=predict_seq)\n",
        "#Create a model checkpoint to store model after each epoch if loss reduces\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('char_rnn.h5',monitor='loss',save_best_only=True, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG0tPWmHkgYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aa753db-fb4d-446e-c74d-15d267982b38"
      },
      "source": [
        "batch_size = 64\n",
        "train_generator = batch_generator(batch_size=batch_size)\n",
        "model.fit_generator(train_generator, epochs=1, steps_per_epoch=(len(book_num)-sequence_length)//batch_size, callbacks=[model_checkpoint, lambda_checkpoint])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "12118/12119 [============================>.] - ETA: 0s - loss: 0.6809\n",
            "Epoch 00001: loss improved from inf to 0.68086, saving model to char_rnn.h5\n",
            "\n",
            "\n",
            "Output sequence after epoch  0  :\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "(1, 100, 67)\n",
            "selding the  and and that im an at she tommnthon t\n",
            "12119/12119 [==============================] - 2142s 177ms/step - loss: 0.6809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbc84032cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RZlzRD0q5sZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}